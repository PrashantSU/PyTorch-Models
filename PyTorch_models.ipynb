{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIb7Nui77r_v"
      },
      "source": [
        "PyTorch models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zr3yasQmk5UI"
      },
      "source": [
        "---\n",
        "\n",
        "How to Use This Notebook\n",
        "---\n",
        "\n",
        "**Recommended Setup**\n",
        "- For the best experience, **run this notebook on [Google Colab](https://colab.research.google.com/)**—especially if your local machine is slow.  \n",
        "- In Colab, **enable GPU support** by going to:  \n",
        "  `Runtime > Change runtime type > Hardware accelerator > GPU`\n",
        "\n",
        "\n",
        "**Homework Tasks**\n",
        "\n",
        " - Homework tasks are clearly marked throughout the notebook in the following format:\n",
        "\n",
        "   > ---\n",
        "\n",
        "   > <span style=\"color:red\"><b>TASK X</b> - [<i>some text</i>]:</span>\n",
        "\n",
        "   > ---\n",
        "\n",
        "   > ```Your code ....```\n",
        "\n",
        "   > ---\n",
        "\n",
        "   > *End of Task X.* [*Instructions for passing*]\n",
        "\n",
        " - For each task:\n",
        "   - **Complete the code** where indicated.\n",
        "   - **Upload the required results** from each task to **Homework 2 – Code** on [NextIlearn](https://nextilearn.dsv.su.se).\n",
        "\n",
        " - Once you've finished all the tasks:\n",
        "   Submit your **entire completed notebook (including your code!)** to **Homework 2 – Notebook** on [NextIlearn](https://nextilearn.dsv.su.se).\n",
        "\n",
        "**Important:**  \n",
        "Your submission will **only be graded if both files** (code + notebook) are uploaded **before the deadline**. Late submissions are **not accepted**, regardless of technical issues like bad internet connection.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIH0AWH2_jxD"
      },
      "source": [
        "This lab will teach how to use PyTorch by making a simple neural network model. Regradless of model's complexity, creating any model can be completed in a similar way. We will use the **Fashion MNIST** dataset, one of the variants of the MNIST dataset. It has the same property as a normal MNIST, with the same size (28*28) and the same number of classes (10), but the images represent fashion items rather than handwritten digits, which means it might have more complexity than normal MNIST.\n",
        "\n",
        "Because of its complexity in each class, the problem is significantly more challenging than normal MNIST. For example, a simple linear model reaches about 92% accuracy on MNIST, but only about 83% on Fashion MNIST. Below is an example of Fashion MNIST."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gQUsFpCD0aP"
      },
      "source": [
        "\n",
        "![alt text](https://github.com/zalandoresearch/fashion-mnist/raw/master/doc/img/fashion-mnist-sprite.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBXx3rp8D2Nm"
      },
      "source": [
        "\n",
        "In today's lab, we will first try to create a simple fully connected network model and check its basic performance on Fashion MNIST.\n",
        "\n",
        "Based on your local machine's performance, the task might take a long time, so it is recommended to use the [Google Colab](https://colab.research.google.com/) since it can handle the lab contents with no processing bottleneck."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_ChFhB0bauM"
      },
      "source": [
        "### Contents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkiDj5c8beHt"
      },
      "source": [
        "- Import PyTorch and load a sample dataset\n",
        "- Sequential fully connected network\n",
        "- Other useful functions (Saving/Loading)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDXwomm0bxug"
      },
      "source": [
        "### Section 1: Import PyTorch and load a sample dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uI9hfGXIA6Ek"
      },
      "source": [
        "You should be able to install PyTorch by using `pip`. You do not need to specify a GPU version."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jzUBH9xhn0JL"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install numpy torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y7mgvEN8mtN6"
      },
      "outputs": [],
      "source": [
        "import torch as pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8zL6JdKIasB"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "1Ek6pMT_pdg_",
        "outputId": "84e26f26-d2ca-465b-eb86-23e4924f11a6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.6.0+cu124'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "# version?\n",
        "pt.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhFeXn8MgFT2"
      },
      "source": [
        "We will use the [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist) data available in github, which has 70,000 article images. Each example is a 28x28 grayscale image, associated with a label from 10 classes.\n",
        "\n",
        "Since it is on github we can simple get it by using `git clone [repo] [folder]`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McfKi-cJn0JP",
        "outputId": "0ae9b385-ddb0-4c20-bee3-ffa4d834afd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'data'...\n",
            "remote: Enumerating objects: 762, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 762 (delta 0), reused 2 (delta 0), pack-reused 758 (from 1)\u001b[K\n",
            "Receiving objects: 100% (762/762), 105.85 MiB | 14.56 MiB/s, done.\n",
            "Resolving deltas: 100% (444/444), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/zalandoresearch/fashion-mnist data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6efgvJL-WwWu"
      },
      "source": [
        "#### Dataset handling: Traditional way with scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lga5zwx6BJti"
      },
      "source": [
        "Datasets can be found in diverse locations -- e.g. on [github](https://github.com/), [zenodo](https://zenodo.org/), [huggingface](https://huggingface.co/docs/hub/en/datasets), [kaggle](https://www.kaggle.com/datasets) or **your companies server**. Some Python modules like `torch` and `tensorflow` also have their own easy-to-use versions of standard datasets specialised to the specific library. For a fast, but less general alternative to this tutorial, see [here](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html). **The linked tutorial is for interrested students and not part of this assignment!**\n",
        "\n",
        "If the dataset is hosted on github or similar, the first step is to check the description: [https://github.com/zalandoresearch/fashion-mnist](https://github.com/zalandoresearch/fashion-mnist#get-the-data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SSWdpC1tjnL"
      },
      "source": [
        "Lets check out the `mnist_reader` they mention:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpYgIPJnr4Cz",
        "outputId": "2ad81ebf-be97-4769-f46a-eb68f2b44d47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "def load_mnist(path, kind='train'):\n",
            "    import os\n",
            "    import gzip\n",
            "    import numpy as np\n",
            "\n",
            "    \"\"\"Load MNIST data from `path`\"\"\"\n",
            "    labels_path = os.path.join(path,\n",
            "                               '%s-labels-idx1-ubyte.gz'\n",
            "                               % kind)\n",
            "    images_path = os.path.join(path,\n",
            "                               '%s-images-idx3-ubyte.gz'\n",
            "                               % kind)\n",
            "\n",
            "    with gzip.open(labels_path, 'rb') as lbpath:\n",
            "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n",
            "                               offset=8)\n",
            "\n",
            "    with gzip.open(images_path, 'rb') as imgpath:\n",
            "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n",
            "                               offset=16).reshape(len(labels), 784)\n",
            "\n",
            "    return images, labels\n"
          ]
        }
      ],
      "source": [
        "!cat data/utils/mnist_reader.py # linux / mac\n",
        "#!type data\\utils\\mnist_reader.py # windows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IY-Nz93XtsRy"
      },
      "source": [
        "What values does the parameter `kind` take?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NXvbQYytQfW",
        "outputId": "e27300be-f418-4fb7-fcd7-1366d4d1784f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['t10k-images-idx3-ubyte.gz',\n",
              " 'train-images-idx3-ubyte.gz',\n",
              " 't10k-labels-idx1-ubyte.gz',\n",
              " 'unzipped',\n",
              " 'train-labels-idx1-ubyte.gz']"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ],
      "source": [
        "import os\n",
        "os.listdir('data/data/fashion')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpsK-umdt4pc"
      },
      "source": [
        "Let's load the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_i0BcD_qwx0"
      },
      "outputs": [],
      "source": [
        "# import mnist_reader:\n",
        "import data.utils.mnist_reader as mnist_reader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2DoMiOnplgm"
      },
      "outputs": [],
      "source": [
        "# load data:\n",
        "X_train_full, y_train_full = mnist_reader.load_mnist('data/data/fashion', kind='train')\n",
        "X_test, y_test = mnist_reader.load_mnist('data/data/fashion', kind='t10k')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9KfXaFeBQLY"
      },
      "source": [
        "This dataset is loaded as a NumPy array which we learned before in Lab 1. You can use all the methods you learned to check the properties of the dataset, like **shape** or **describe**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQGzWUZABSdD",
        "outputId": "179e5c4b-c834-4bab-fdd4-05a71bf199c0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ],
      "source": [
        "# type?\n",
        "type(X_train_full)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rA4f__FUppwQ",
        "outputId": "d55bdd82-d6cc-4e01-e12f-a4946c8c404b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 784), (10000, 784))"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ],
      "source": [
        "# shape?\n",
        "X_train_full.shape, X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbRWMKbUZnJJ",
        "outputId": "48e6f880-6dcc-4022-adb9-ac4b1c7f6dac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ],
      "source": [
        "np.unique(y_train_full)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeSk4-jABU95"
      },
      "source": [
        "As the dataset is composed of grayscale pixels, the datatype of it is unsigned integer. The dataset also has a pixed range [0, 255] so it does not need to take higher bit than 8."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdNJONOHptj6",
        "outputId": "7aff0abf-fd8b-4de5-8fb5-f73a4df53de9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('uint8')"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ],
      "source": [
        "# dtype?\n",
        "X_train_full.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-ZE6WfngbYs"
      },
      "source": [
        "Besides that, PyTorch models are also usually evaluated by one more separate set called validation set as training is an iterative and time-consuming process and we do not know when we need to stop clearly. So we would like to estimate the right time to interrupt the training process by checking its performance for each iteration.\n",
        "\n",
        "To create a validation set, there can be many options, we can explicitly split the dataset using index, or we can just use a training set but with the option stating we want to validate, when we actually fit the model. However, this time we will use scikit-learn's `train_test_split` method to create a validation set as it can provide a nice stratification option."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUEmqGNGoZ_W"
      },
      "source": [
        "We need a simiple normalization - as we all know the graysclae ranges from 0 to 255..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lb6n6PzLgjRj"
      },
      "outputs": [],
      "source": [
        "# Introduced in the coursebook\n",
        "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azOEHFspR7u5"
      },
      "outputs": [],
      "source": [
        "X_test = X_test / 255."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqtvJAWxvhEP"
      },
      "source": [
        "---\n",
        "\n",
        "<span style=\"color:red\"><b>TASK 1</b> - Stratified Split:</span>\n",
        "\n",
        "---\n",
        "\n",
        "Replace the above simple training/validation split with a **stratified** one (50% train, 50% validation):\n",
        "  - Use `X_train_full` and `y_train_full`\n",
        "  - Enable `shuffle` and `stratification`\n",
        "\n",
        "Use [`sklearn.model_selection.train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html). Print and check their shapes afterward!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQuXXouFLDRN"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# normalize:\n",
        "X_train_full = X_train_full / 255.\n",
        "\n",
        "# stratified split (50% train, 50% validation):\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    X_train_full,\n",
        "    y_train_full,\n",
        "    test_size=0.5,\n",
        "    random_state=42,\n",
        "    shuffle=True,\n",
        "    stratify=y_train_full\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4gVzDXcR7u7"
      },
      "outputs": [],
      "source": [
        "# shape?\n",
        "#continue"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_f0SkwQR7u7"
      },
      "source": [
        "---\n",
        "\n",
        "*End of Task 1. Copy your final code to **Homework 2 - Code** on **NextIlearn***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWTSsrnEF2XC"
      },
      "source": [
        "Here we prepared the class names of the fashion MNIST dataset for your convenience."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRc7tKoIsFx4"
      },
      "outputs": [],
      "source": [
        "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "eBOMMsxAxrfj",
        "outputId": "e42ca213-86b8-4b34-c505-be24768a51c9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'T-shirt/top'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 96
        }
      ],
      "source": [
        "# Use the numeric label to get the class name, e.g:\n",
        "class_names[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ch49P29iEDxC"
      },
      "source": [
        "We can also try to see each data instance by using **plt.imshow**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "FSwEtbA6KmFg",
        "outputId": "3d9fb9ea-d259-4b83-ad28-a44d71fa7537"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "i = np.random.randint(0, X_train.shape[0])\n",
        "plt.imshow(X_train[i].reshape((28, 28)), cmap='gray') # cmap to make it recognize grayscale\n",
        "plt.xlabel(class_names[y_train[i]])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngPR-OZKyStX"
      },
      "source": [
        "#### Optimizing memory consuption using pipelines:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2w2ohRDo2eW"
      },
      "source": [
        "Imagine taking the above approach with very large datasets (e.g. used for training modern LLMs). Loading all the data before training would exceed RAM and VRAM of almost any computer.\n",
        "\n",
        "Therefore, we are going to use the [`torch.utils.data.Dataset`](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) API:\n",
        "\n",
        "---\n",
        "***An abstract class representing a Dataset.***\n",
        "\n",
        "*All datasets that represent a map from keys to data samples should subclass it. All subclasses should overwrite* `__getitem__()`*, supporting fetching a data sample for a given key. Subclasses could also optionally overwrite* `__len__()`*, which is expected to return the size of the dataset by many Sampler implementations and the default options of DataLoader. Subclasses could also optionally implement* `__getitems__()`*, for speedup batched samples loading. This method accepts list of indices of samples of batch and returns list of samples.*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xcvyxGDerVFS"
      },
      "outputs": [],
      "source": [
        "from numpy.typing import NDArray\n",
        "from typing import Tuple\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class FashionMNIST(Dataset):\n",
        "  def __init__(self, X:NDArray[np.int8], y:NDArray[np.int8]) -> None:\n",
        "    # normalize:\n",
        "    self.X = X.astype(np.float32) / 255.0\n",
        "    self.y = y\n",
        "\n",
        "  def __len__(self) -> int:\n",
        "    return len(self.y)\n",
        "\n",
        "  def __getitem__(self, idx:int) -> int:\n",
        "    return self.X[idx], self.y[idx]\n",
        "\n",
        "  @staticmethod\n",
        "  def create_split(fraction_train:float, fraction_validation:float, fraction_test:float) -> Tuple[Dataset, Dataset, Dataset]:\n",
        "    assert fraction_train + fraction_validation + fraction_test == 1.0\n",
        "\n",
        "    # load data:\n",
        "    train = mnist_reader.load_mnist('data/data/fashion', kind='train')\n",
        "    t10k  = mnist_reader.load_mnist('data/data/fashion', kind='t10k')\n",
        "\n",
        "    data   = np.concatenate((train[0], t10k[0]), axis=0)\n",
        "    labels = np.concatenate((train[1], t10k[1]), axis=0)\n",
        "\n",
        "    # split data:\n",
        "    n = len(labels)\n",
        "    n_train = int(n * fraction_train)\n",
        "    n_validation = int(n * fraction_validation)\n",
        "\n",
        "    data_train = FashionMNIST(\n",
        "        data[:n_train],\n",
        "        labels[:n_train]\n",
        "    )\n",
        "    data_valid = FashionMNIST(\n",
        "        data[n_train:n_train+n_validation],\n",
        "        labels[n_train:n_train+n_validation]\n",
        "    )\n",
        "    data_test = FashionMNIST(\n",
        "        data[n_train+n_validation:],\n",
        "        labels[n_train+n_validation:]\n",
        "    )\n",
        "\n",
        "    return data_train, data_valid, data_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0v0JjVOk57s"
      },
      "source": [
        "It works like a list of tuples `(X, y)` in Python:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCOTVO81lZyD"
      },
      "outputs": [],
      "source": [
        "data, _, _ = FashionMNIST.create_split(.7, .1, .2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOjOC4aIlpfp",
        "outputId": "ac4d01b0-0a7a-4eaa-e97e-c437b334f90a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49000"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ],
      "source": [
        "# call to __len__:\n",
        "len(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILFLbrYUlrdL",
        "outputId": "5b1b8b59-bf35-4608-b87f-7ce9e4e23892"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.08627451,\n",
              "        0.34509805, 0.7372549 , 0.6745098 , 0.5176471 , 0.49019608,\n",
              "        0.5529412 , 0.78039217, 0.56078434, 0.03529412, 0.        ,\n",
              "        0.        , 0.        , 0.00392157, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.00392157, 0.        , 0.        , 0.07843138,\n",
              "        0.5137255 , 0.78039217, 0.80784315, 0.76862746, 0.7921569 ,\n",
              "        0.9490196 , 1.        , 1.        , 0.98039216, 0.87058824,\n",
              "        0.77254903, 0.80784315, 0.7372549 , 0.49411765, 0.06666667,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
              "        0.        , 0.13725491, 0.8392157 , 0.7490196 , 0.7176471 ,\n",
              "        0.69803923, 0.6862745 , 0.65882355, 0.5882353 , 0.63529414,\n",
              "        0.62352943, 0.59607846, 0.61960787, 0.7019608 , 0.7176471 ,\n",
              "        0.7411765 , 0.7647059 , 0.7254902 , 0.32156864, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.6666667 ,\n",
              "        0.74509805, 0.6745098 , 0.69411767, 0.6901961 , 0.67058825,\n",
              "        0.6627451 , 0.63529414, 0.60784316, 0.5803922 , 0.6039216 ,\n",
              "        0.6627451 , 0.68235296, 0.6862745 , 0.6862745 , 0.69411767,\n",
              "        0.7176471 , 0.7372549 , 0.04705882, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.09803922, 0.7607843 , 0.7058824 , 0.69803923,\n",
              "        0.68235296, 0.72156864, 0.73333335, 0.7411765 , 0.73333335,\n",
              "        0.72156864, 0.70980394, 0.7411765 , 0.78431374, 0.77254903,\n",
              "        0.75686276, 0.74509805, 0.69803923, 0.6862745 , 0.7607843 ,\n",
              "        0.3529412 , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.16470589,\n",
              "        0.85490197, 0.7490196 , 0.77254903, 0.8156863 , 0.8       ,\n",
              "        0.827451  , 0.81960785, 0.8235294 , 0.83137256, 0.827451  ,\n",
              "        0.8392157 , 0.84313726, 0.8352941 , 0.8392157 , 0.827451  ,\n",
              "        0.827451  , 0.7490196 , 0.78431374, 0.61960787, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.34509805, 0.8666667 , 0.84313726,\n",
              "        0.8509804 , 0.85882354, 0.827451  , 0.7254902 , 0.5882353 ,\n",
              "        0.4627451 , 0.41960785, 0.3882353 , 0.34509805, 0.3254902 ,\n",
              "        0.3529412 , 0.5294118 , 0.83137256, 0.79607844, 0.8117647 ,\n",
              "        0.85882354, 0.6627451 , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.10588235, 0.4627451 , 0.63529414, 0.15686275,\n",
              "        0.        , 0.        , 0.        , 0.03921569, 0.07450981,\n",
              "        0.10980392, 0.15294118, 0.18431373, 0.14117648, 0.        ,\n",
              "        0.        , 0.79607844, 0.9019608 , 0.8627451 , 0.79607844,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.5411765 , 0.53333336,\n",
              "        0.2784314 , 0.27058825, 0.21176471, 0.84705883, 0.8509804 ,\n",
              "        0.79607844, 0.72156864, 0.65882355, 0.6392157 , 0.63529414,\n",
              "        0.6392157 , 0.69803923, 0.8666667 , 0.7294118 , 0.14901961,\n",
              "        0.10196079, 0.02745098, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.2627451 , 0.5254902 , 0.6039216 , 0.8784314 ,\n",
              "        0.5058824 , 0.25882354, 0.31764707, 0.45882353, 0.5058824 ,\n",
              "        0.5019608 , 0.5176471 , 0.5372549 , 0.5137255 , 0.5058824 ,\n",
              "        0.3372549 , 0.28627452, 0.6156863 , 0.5921569 , 0.5254902 ,\n",
              "        0.84705883, 0.07058824, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.79607844,\n",
              "        0.7764706 , 0.6745098 , 0.7176471 , 0.80784315, 1.        ,\n",
              "        1.        , 0.98039216, 0.9529412 , 0.9411765 , 0.9372549 ,\n",
              "        0.92156863, 0.93333334, 0.95686275, 1.        , 0.93333334,\n",
              "        0.72156864, 0.627451  , 0.3372549 , 0.38431373, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.47843137, 0.7372549 , 0.8784314 ,\n",
              "        0.5921569 , 0.4117647 , 0.49803922, 0.38039216, 0.39215687,\n",
              "        0.4117647 , 0.44705883, 0.45882353, 0.45882353, 0.44313726,\n",
              "        0.40392157, 0.38431373, 0.43529412, 0.5568628 , 0.99607843,\n",
              "        0.7490196 , 1.        , 0.19215687, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.6392157 , 0.7019608 , 0.78431374, 0.37254903, 0.6039216 ,\n",
              "        0.7764706 , 0.77254903, 0.78431374, 0.78431374, 0.7764706 ,\n",
              "        0.77254903, 0.7764706 , 0.78039217, 0.7921569 , 0.78431374,\n",
              "        0.6901961 , 0.3372549 , 0.80784315, 0.6156863 , 0.63529414,\n",
              "        0.03921569, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.77254903, 0.7882353 ,\n",
              "        0.8980392 , 0.2784314 , 0.5647059 , 0.7607843 , 0.70980394,\n",
              "        0.7176471 , 0.7019608 , 0.7137255 , 0.7058824 , 0.7019608 ,\n",
              "        0.7058824 , 0.74509805, 0.7254902 , 0.77254903, 0.29803923,\n",
              "        0.85882354, 0.7254902 , 0.7882353 , 0.13333334, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.78039217, 0.75686276, 0.8862745 , 0.22745098,\n",
              "        0.6039216 , 0.7529412 , 0.72156864, 0.73333335, 0.72156864,\n",
              "        0.7294118 , 0.72156864, 0.7254902 , 0.7176471 , 0.7529412 ,\n",
              "        0.7490196 , 0.78431374, 0.21960784, 0.85882354, 0.79607844,\n",
              "        0.8117647 , 0.23529412, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.7882353 ,\n",
              "        0.7607843 , 0.8784314 , 0.16078432, 0.6392157 , 0.74509805,\n",
              "        0.7294118 , 0.7294118 , 0.72156864, 0.7254902 , 0.7176471 ,\n",
              "        0.7254902 , 0.69803923, 0.74509805, 0.7607843 , 0.7921569 ,\n",
              "        0.12941177, 0.827451  , 0.78431374, 0.80784315, 0.28627452,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.7882353 , 0.77254903, 0.87058824,\n",
              "        0.06666667, 0.6745098 , 0.74509805, 0.7294118 , 0.73333335,\n",
              "        0.7137255 , 0.7294118 , 0.7254902 , 0.73333335, 0.7058824 ,\n",
              "        0.73333335, 0.75686276, 0.7921569 , 0.10196079, 0.83137256,\n",
              "        0.7921569 , 0.79607844, 0.29803923, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.78431374, 0.77254903, 0.8745098 , 0.        , 0.69411767,\n",
              "        0.7411765 , 0.72156864, 0.7254902 , 0.69803923, 0.72156864,\n",
              "        0.7176471 , 0.72156864, 0.7058824 , 0.7176471 , 0.7411765 ,\n",
              "        0.79607844, 0.13725491, 0.76862746, 0.79607844, 0.79607844,\n",
              "        0.32941177, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.78431374, 0.77254903,\n",
              "        0.8745098 , 0.        , 0.7254902 , 0.73333335, 0.7254902 ,\n",
              "        0.73333335, 0.7058824 , 0.72156864, 0.7137255 , 0.7176471 ,\n",
              "        0.69803923, 0.7137255 , 0.7176471 , 0.8039216 , 0.17254902,\n",
              "        0.62352943, 0.8117647 , 0.7882353 , 0.33333334, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.73333335, 0.7764706 , 0.88235295, 0.        ,\n",
              "        0.7607843 , 0.7372549 , 0.72156864, 0.7254902 , 0.7058824 ,\n",
              "        0.7176471 , 0.7176471 , 0.72156864, 0.70980394, 0.70980394,\n",
              "        0.69411767, 0.80784315, 0.18039216, 0.5058824 , 0.827451  ,\n",
              "        0.78431374, 0.34509805, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.02352941, 0.7294118 ,\n",
              "        0.78431374, 0.827451  , 0.        , 0.78039217, 0.7411765 ,\n",
              "        0.72156864, 0.72156864, 0.7254902 , 0.7137255 , 0.7176471 ,\n",
              "        0.72156864, 0.7254902 , 0.7137255 , 0.6862745 , 0.8039216 ,\n",
              "        0.19607843, 0.38039216, 0.84705883, 0.77254903, 0.3647059 ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.01960784, 0.7254902 , 0.8       , 0.72156864,\n",
              "        0.        , 0.7921569 , 0.7372549 , 0.7137255 , 0.7137255 ,\n",
              "        0.7176471 , 0.7176471 , 0.72156864, 0.7137255 , 0.7058824 ,\n",
              "        0.7137255 , 0.68235296, 0.7921569 , 0.24705882, 0.23137255,\n",
              "        0.8627451 , 0.76862746, 0.36862746, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.01960784,\n",
              "        0.72156864, 0.80784315, 0.6156863 , 0.        , 0.8       ,\n",
              "        0.73333335, 0.73333335, 0.7411765 , 0.7529412 , 0.74509805,\n",
              "        0.74509805, 0.7490196 , 0.74509805, 0.73333335, 0.7176471 ,\n",
              "        0.7921569 , 0.30588236, 0.13725491, 0.87058824, 0.77254903,\n",
              "        0.37254903, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.01960784, 0.7176471 , 0.8156863 ,\n",
              "        0.49803922, 0.        , 0.77254903, 0.6509804 , 0.6       ,\n",
              "        0.58431375, 0.58431375, 0.57254905, 0.5803922 , 0.58431375,\n",
              "        0.5882353 , 0.5921569 , 0.61960787, 0.7490196 , 0.3529412 ,\n",
              "        0.03137255, 0.8745098 , 0.7647059 , 0.3882353 , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.02352941, 0.72156864, 0.8156863 , 0.44705883, 0.        ,\n",
              "        0.8       , 0.6784314 , 0.6313726 , 0.7058824 , 0.6901961 ,\n",
              "        0.6745098 , 0.6784314 , 0.6784314 , 0.68235296, 0.6901961 ,\n",
              "        0.63529414, 0.7921569 , 0.4509804 , 0.        , 0.8980392 ,\n",
              "        0.78039217, 0.4117647 , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.03529412, 0.69803923,\n",
              "        0.8       , 0.4509804 , 0.        , 0.4745098 , 0.5294118 ,\n",
              "        0.44705883, 0.45882353, 0.44705883, 0.44705883, 0.45882353,\n",
              "        0.4627451 , 0.46666667, 0.45882353, 0.44313726, 0.5764706 ,\n",
              "        0.24705882, 0.        , 0.88235295, 0.76862746, 0.41960785,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.07058824, 0.7058824 , 0.80784315, 0.5137255 ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.8784314 , 0.77254903, 0.48235294, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.5529412 , 0.5921569 , 0.29803923, 0.        , 0.00392157,\n",
              "        0.00392157, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.52156866, 0.654902  ,\n",
              "        0.28627452, 0.        , 0.        , 0.        ], dtype=float32),\n",
              " np.uint8(2))"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ],
      "source": [
        "# call to __getitem__:\n",
        "data[5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1u-U7X-fXCB"
      },
      "source": [
        "But the above implementation still loads everything at the time of instantiation of the `FashionMNIST` class. So let's transform the data into a format that you see more often with big datasets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EADlbbqB01Kw"
      },
      "outputs": [],
      "source": [
        "# unzip data:\n",
        "target_dir = 'data/data/fashion/unzipped'\n",
        "os.makedirs(target_dir, exist_ok=True)\n",
        "\n",
        "train = mnist_reader.load_mnist('data/data/fashion', kind='train')\n",
        "t10k  = mnist_reader.load_mnist('data/data/fashion', kind='t10k')\n",
        "\n",
        "data = np.concatenate((train[0], t10k[0]), axis=0)\n",
        "labels = np.concatenate((train[1], t10k[1]), axis=0)\n",
        "\n",
        "for i, x in enumerate(data):\n",
        "  file = os.path.join(target_dir, f'img_{i:d}.npy')\n",
        "  with open(file, 'wb') as f:\n",
        "    np.save(f, x.reshape((28, 28)))\n",
        "\n",
        "with open(os.path.join(target_dir, 'labels.npy'), 'wb') as f:\n",
        "  np.save(f, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lv0YptsZ-QaG",
        "outputId": "28f4a809-9f47-41ee-eed4-96bf736853ff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['img_67431.npy',\n",
              " 'img_4951.npy',\n",
              " 'img_1250.npy',\n",
              " 'img_41482.npy',\n",
              " 'img_8223.npy',\n",
              " 'img_6140.npy',\n",
              " 'img_35312.npy',\n",
              " 'img_55257.npy',\n",
              " 'img_56894.npy',\n",
              " 'img_19954.npy']"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ],
      "source": [
        "os.listdir(target_dir)[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrICJqXvjc1Y"
      },
      "source": [
        "---\n",
        "\n",
        "<span style=\"color:red\"><b>TASK 2</b> - Dataset:</span>\n",
        "\n",
        "---\n",
        "\n",
        "Complete the following class.\n",
        "- It should load every single sample dynamically from disk when it is requested and this way keep memory consumption to a minimum.\n",
        "- Use your code from Task 1 to create stratified splits using the `stratify` and `shuffle` arguments of `create_split`.\n",
        "- Use the variable `target_dir` as the path to the unzipped data.\n",
        "- **Make sure it produces the the right type of outputs (see type hintig and class above)!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VmiKviaXkHYb"
      },
      "outputs": [],
      "source": [
        "class FashionMNIST(Dataset):\n",
        "  def __init__(self, indices:NDArray[np.int32], labels:NDArray[np.int8]) -> None:\n",
        "    self.indices = indices\n",
        "    self.labels  = labels\n",
        "\n",
        "  def __len__(self) -> int:\n",
        "    return len(self.indices)\n",
        "\n",
        "  def __getitem__(self, idx:int) -> int:\n",
        "    # complete\n",
        "    i = self.indices[idx]\n",
        "    sample_path = os.path.join(target_dir, f'img_{i}.npy')\n",
        "    sample = np.load(sample_path).astype(np.float32) / 255.0\n",
        "    label = self.labels[idx]\n",
        "    return sample, label\n",
        "\n",
        "  @staticmethod\n",
        "  def create_split(fraction_train:float, fraction_validation:float, fraction_test:float, stratify:bool=True, shuffle:bool=True) -> Tuple[Dataset, Dataset, Dataset]:\n",
        "    assert fraction_train + fraction_validation + fraction_test == 1.0\n",
        "    # complete\n",
        "\n",
        "    labels_path = os.path.join(target_dir, 'labels.npy')\n",
        "    labels = np.load(labels_path)\n",
        "\n",
        "    indices = np.arange(len(labels))\n",
        "\n",
        "    if shuffle:\n",
        "      train_idx, mix_idx, y_train, y_mix = train_test_split(indices, labels, test_size=(fraction_test+fraction_validation), stratify=labels if stratify else None, shuffle=True, random_state=0)\n",
        "      val_idx, test_idx, y_val, y_test = train_test_split(mix_idx, y_mix, test_size=(fraction_test/(fraction_validation+fraction_test)),stratify=y_mix if stratify else None, shuffle=True, random_state=0)\n",
        "    else:\n",
        "      train_idx, mix_idx, y_train, y_mix = train_test_split(indices, labels, test_size=(fraction_test+fraction_validation), stratify=None, shuffle=False)\n",
        "      val_idx, test_idx, y_val, y_test = train_test_split(mix_idx, y_mix, test_size=(fraction_test/(fraction_validation+fraction_test)),stratify= None, shuffle=False)\n",
        "\n",
        "    data_train = FashionMNIST(train_idx, y_train)\n",
        "    data_valid = FashionMNIST(val_idx, y_val)\n",
        "    data_test = FashionMNIST(test_idx, y_test)\n",
        "\n",
        "    return data_train, data_valid, data_test\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQxU6CLfR7vD"
      },
      "source": [
        "---\n",
        "\n",
        "*End of Task 2. Copy your final code to **Homework 2 - Code** on **NextIlearn***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRzLUn4kGGVU"
      },
      "source": [
        "Our objective is to create a model with the high accuracy on this dataset. Let's start to create our first model!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ox0oodObDPH"
      },
      "source": [
        "**Shuffling and batching**: Using [`torch.utils.data.DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader), you can easily shuffle and batch the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QdYJGAsARQxB"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "BATCH_SIZE = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZmqQ9W2pp5b"
      },
      "outputs": [],
      "source": [
        "data_train, data_valid, data_test = FashionMNIST.create_split(.7, .1, .2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W2dJNcKrESEU"
      },
      "outputs": [],
      "source": [
        "loader_train = DataLoader(data_train,             # dataset from which to load the data.\n",
        "                          batch_size=BATCH_SIZE,  # how many samples per batch to load (default: 1).\n",
        "                          shuffle=True,           # set to True to have the data reshuffled at every epoch (default: False).\n",
        "                          sampler=None,           # defines the strategy to draw samples from the dataset. Can be any Iterable with __len__ implemented.\n",
        "                                                  # If specified, shuffle must not be specified.\n",
        "                          batch_sampler=None,     # like sampler, but returns a batch of indices at a time. Mutually exclusive with batch_size, shuffle, sampler, and drop_last.\n",
        "                          drop_last=False)        # set to True to drop the last incomplete batch, if the dataset size is not divisible by the batch size.\n",
        "                                                  # If False and the size of dataset is not divisible by the batch size, then the last batch will be smaller. (default: False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tj964nU9EVbq"
      },
      "outputs": [],
      "source": [
        "# validation set does not need to be repeated and shuffled since it all will be used at once - but MUST be batched.\n",
        "loader_valid = DataLoader(data_valid,\n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          shuffle=False,\n",
        "                          sampler=None,\n",
        "                          batch_sampler=None,\n",
        "                          drop_last=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nu56t0MPO1PF"
      },
      "outputs": [],
      "source": [
        "# test set does not need to be repeated and shuffled since it all will be used at once - but MUST be batched.\n",
        "loader_test  = DataLoader(data_test,\n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          shuffle=False,\n",
        "                          sampler=None,\n",
        "                          batch_sampler=None,\n",
        "                          drop_last=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ewz-SbwJxZ1t"
      },
      "source": [
        "### Section 2: Sequential fully connected network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Fh7PjMWqOnS"
      },
      "source": [
        "#### Instantiating the network:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGuxZ7HZgpwm"
      },
      "source": [
        "The standard way to create a PyTorch model is to override the [`torch.nn.Module`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module) class. To create a model you need to override the following methods:\n",
        "- `__init__(self, ...) -> None`: Initializes the module and instantiates all the layers and functions.\n",
        "- `forward(self, x) -> y`: implements the forward pass through the network.\n",
        "\n",
        "When you create a layer (e.g. [`torch.nn.Linear`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear)), you should specify **in_features** and **out_features**. Don't forget to apply an **activation function** in the forward pass."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dpDMjCbExvzN"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CustomNetwork(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super().__init__()\n",
        "        self.layer1 = nn.Linear(in_features=784, out_features=100, bias=True)\n",
        "        self.layer2 = nn.Linear(in_features=100, out_features=len(class_names), bias=True)\n",
        "\n",
        "    def forward(self, x:pt.Tensor) -> pt.Tensor:\n",
        "        x = F.relu(self.layer1(x))\n",
        "        return F.softmax(self.layer2(x), dim=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvjomL9CJcrr"
      },
      "source": [
        "We can visualize the model using **keras.utils.plot_model**. It helps to figue out (or validate) the structure of complete models having multiple paths."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iLn73SNJenS",
        "outputId": "abd3b1b8-e667-4ca5-cc1d-a2b4d018eae6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                  [-1, 100]          78,500\n",
            "            Linear-2                   [-1, 10]           1,010\n",
            "================================================================\n",
            "Total params: 79,510\n",
            "Trainable params: 79,510\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 0.30\n",
            "Estimated Total Size (MB): 0.31\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "model = CustomNetwork()\n",
        "summary(model, input_size=(784,), device='cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_iVtGfSEe7b"
      },
      "source": [
        "Summarization of model parameters is only possible when the model has an input information as it needs to calculate the fully connected parameters from the input layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEOcLYKLEpgw"
      },
      "source": [
        "A model instance has various attributes to get layers, weights - which are just for your reference to check the real values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5iYpVqcwYL9",
        "outputId": "8c0d71fd-0e95-4a0a-8e14-bdad1539d7e4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Linear(in_features=784, out_features=100, bias=True),\n",
              " Linear(in_features=100, out_features=10, bias=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ],
      "source": [
        "# You can get a generator object of properties of type `torch.nn.Module` using `children()`:\n",
        "# !!! in order of instantiation !!!\n",
        "list(model.children())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFwCNTJ4nGyW",
        "outputId": "87917601-7ca2-45dc-9d63-c55fde40879c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('layer1', Linear(in_features=784, out_features=100, bias=True)),\n",
              " ('layer2', Linear(in_features=100, out_features=10, bias=True))]"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ],
      "source": [
        "list(model.named_children())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJcb7xZtpEAZ",
        "outputId": "3e1b9b6c-4518-40af-e6fc-a53abfc197a3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=784, out_features=100, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ],
      "source": [
        "model.get_submodule('layer1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdnS08_Lom1s",
        "outputId": "6a38eee2-260c-4d56-e640-f562c59f6673"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('',\n",
              "  CustomNetwork(\n",
              "    (layer1): Linear(in_features=784, out_features=100, bias=True)\n",
              "    (layer2): Linear(in_features=100, out_features=10, bias=True)\n",
              "  )),\n",
              " ('layer1', Linear(in_features=784, out_features=100, bias=True)),\n",
              " ('layer2', Linear(in_features=100, out_features=10, bias=True))]"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ],
      "source": [
        "# All modules in the model (including itself):\n",
        "list(model.named_modules())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAa1OQuPnlNF",
        "outputId": "28332550-2e38-4d79-c572-adce8d30f5fa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[-0.0209, -0.0071, -0.0092,  ..., -0.0058, -0.0108,  0.0127],\n",
              "         [ 0.0193, -0.0221,  0.0280,  ...,  0.0059,  0.0077,  0.0223],\n",
              "         [-0.0170, -0.0262, -0.0149,  ..., -0.0343,  0.0167, -0.0227],\n",
              "         ...,\n",
              "         [-0.0189, -0.0238, -0.0340,  ...,  0.0291,  0.0174, -0.0169],\n",
              "         [ 0.0201, -0.0049,  0.0096,  ...,  0.0220,  0.0030, -0.0166],\n",
              "         [-0.0136,  0.0232,  0.0204,  ...,  0.0026,  0.0040, -0.0155]],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-0.0348,  0.0355,  0.0126,  0.0217,  0.0183,  0.0265, -0.0222, -0.0080,\n",
              "         -0.0225, -0.0331, -0.0337,  0.0206, -0.0196, -0.0038,  0.0313, -0.0028,\n",
              "          0.0286,  0.0110,  0.0075,  0.0315,  0.0235,  0.0185,  0.0164, -0.0127,\n",
              "         -0.0352,  0.0116,  0.0116, -0.0097, -0.0303,  0.0037, -0.0098,  0.0274,\n",
              "          0.0306, -0.0019, -0.0173, -0.0233, -0.0303, -0.0147, -0.0038,  0.0186,\n",
              "         -0.0173,  0.0339, -0.0194,  0.0238,  0.0226, -0.0315,  0.0110,  0.0116,\n",
              "         -0.0329,  0.0081,  0.0318,  0.0053, -0.0076,  0.0053, -0.0320,  0.0315,\n",
              "          0.0247, -0.0245,  0.0209,  0.0270, -0.0170, -0.0202, -0.0319, -0.0197,\n",
              "         -0.0299,  0.0126,  0.0053,  0.0124,  0.0266,  0.0266,  0.0084, -0.0068,\n",
              "          0.0316,  0.0271,  0.0262,  0.0330, -0.0124,  0.0127,  0.0150, -0.0121,\n",
              "         -0.0226,  0.0334, -0.0005, -0.0342, -0.0014, -0.0301,  0.0258,  0.0254,\n",
              "          0.0084,  0.0129,  0.0037,  0.0283,  0.0072, -0.0240, -0.0075, -0.0320,\n",
              "          0.0213,  0.0009, -0.0230,  0.0323], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ],
      "source": [
        "# You can get a generator object of parameters (weights) for each submodule using `parameters()`:\n",
        "# !!! in order of instantiation !!!\n",
        "list(model.parameters())[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUW334iaoA7z",
        "outputId": "8de2fd23-d2c2-41dc-9480-0600ec9530af"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('layer1.weight',\n",
              "  Parameter containing:\n",
              "  tensor([[-0.0209, -0.0071, -0.0092,  ..., -0.0058, -0.0108,  0.0127],\n",
              "          [ 0.0193, -0.0221,  0.0280,  ...,  0.0059,  0.0077,  0.0223],\n",
              "          [-0.0170, -0.0262, -0.0149,  ..., -0.0343,  0.0167, -0.0227],\n",
              "          ...,\n",
              "          [-0.0189, -0.0238, -0.0340,  ...,  0.0291,  0.0174, -0.0169],\n",
              "          [ 0.0201, -0.0049,  0.0096,  ...,  0.0220,  0.0030, -0.0166],\n",
              "          [-0.0136,  0.0232,  0.0204,  ...,  0.0026,  0.0040, -0.0155]],\n",
              "         requires_grad=True)),\n",
              " ('layer1.bias',\n",
              "  Parameter containing:\n",
              "  tensor([-0.0348,  0.0355,  0.0126,  0.0217,  0.0183,  0.0265, -0.0222, -0.0080,\n",
              "          -0.0225, -0.0331, -0.0337,  0.0206, -0.0196, -0.0038,  0.0313, -0.0028,\n",
              "           0.0286,  0.0110,  0.0075,  0.0315,  0.0235,  0.0185,  0.0164, -0.0127,\n",
              "          -0.0352,  0.0116,  0.0116, -0.0097, -0.0303,  0.0037, -0.0098,  0.0274,\n",
              "           0.0306, -0.0019, -0.0173, -0.0233, -0.0303, -0.0147, -0.0038,  0.0186,\n",
              "          -0.0173,  0.0339, -0.0194,  0.0238,  0.0226, -0.0315,  0.0110,  0.0116,\n",
              "          -0.0329,  0.0081,  0.0318,  0.0053, -0.0076,  0.0053, -0.0320,  0.0315,\n",
              "           0.0247, -0.0245,  0.0209,  0.0270, -0.0170, -0.0202, -0.0319, -0.0197,\n",
              "          -0.0299,  0.0126,  0.0053,  0.0124,  0.0266,  0.0266,  0.0084, -0.0068,\n",
              "           0.0316,  0.0271,  0.0262,  0.0330, -0.0124,  0.0127,  0.0150, -0.0121,\n",
              "          -0.0226,  0.0334, -0.0005, -0.0342, -0.0014, -0.0301,  0.0258,  0.0254,\n",
              "           0.0084,  0.0129,  0.0037,  0.0283,  0.0072, -0.0240, -0.0075, -0.0320,\n",
              "           0.0213,  0.0009, -0.0230,  0.0323], requires_grad=True))]"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ],
      "source": [
        "list(model.named_parameters())[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyjmrnDXobxo",
        "outputId": "ddff4ae5-e2ec-42c5-bebb-d9c4c6dc3aa4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.0209, -0.0071, -0.0092,  ..., -0.0058, -0.0108,  0.0127],\n",
              "        [ 0.0193, -0.0221,  0.0280,  ...,  0.0059,  0.0077,  0.0223],\n",
              "        [-0.0170, -0.0262, -0.0149,  ..., -0.0343,  0.0167, -0.0227],\n",
              "        ...,\n",
              "        [-0.0189, -0.0238, -0.0340,  ...,  0.0291,  0.0174, -0.0169],\n",
              "        [ 0.0201, -0.0049,  0.0096,  ...,  0.0220,  0.0030, -0.0166],\n",
              "        [-0.0136,  0.0232,  0.0204,  ...,  0.0026,  0.0040, -0.0155]],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ],
      "source": [
        "model.get_parameter('layer1.weight')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06cXyZlQwJca"
      },
      "source": [
        "---\n",
        "\n",
        "<span style=\"color:red\"><b>TASK 3</b> - Simple Network:</span>\n",
        "\n",
        "---\n",
        "\n",
        "The above network is very simple. Implement a better version with the following layers:\n",
        "- One **linear input layer** of 300 perceptrons, with a **ReLu** activation function, followed by a **dropout** layer (use the `dropout` parameter for the ratio).\n",
        "- One **linear hidden layer** of size 200, with a **ReLu** activation function, followed by a **dropout** layer (use the `dropout` parameter for the ratio).\n",
        "- One **linear output layer**, with a **softmax** activation function.\n",
        "\n",
        "Assume that `torch.nn` is already imported as `nn`. Furthermore, `torch.nn.functional` is available as `F`.\n",
        "Make sure the network has the following layers (i.e. use `torch.nn.Dropout` instead of `torch.nn.functional.dropout`):\n",
        "\n",
        "    --------------------------\n",
        "            Layer (type)      \n",
        "    ==========================\n",
        "             Linear-1         \n",
        "            Dropout-2         \n",
        "             Linear-3         \n",
        "            Dropout-4         \n",
        "             Linear-5         \n",
        "    ==========================\n",
        "    Total params: 297,710     \n",
        "    Trainable params: 297,710\n",
        "    Non-trainable params: 0   \n",
        "    --------------------------\n",
        "\n",
        "See [here](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html) for documentation of the `torch.nn.Dropout` layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpYsDHgzwuwI"
      },
      "outputs": [],
      "source": [
        "class CustomNetwork(nn.Module):\n",
        "    def __init__(self, input_dim: int = 784, num_classes: int = 10, dropout: float = 0.2) -> None:\n",
        "        super().__init__()\n",
        "        self.input_layer = nn.Linear(input_dim, 300)   # Linear-1\n",
        "        self.dropout1 = nn.Dropout(dropout)            # Dropout-2\n",
        "\n",
        "        self.hidden_layer = nn.Linear(300, 200)        # Linear-3\n",
        "        self.dropout2 = nn.Dropout(dropout)            # Dropout-4\n",
        "\n",
        "        self.output_layer = nn.Linear(200, num_classes)  # Linear-5\n",
        "\n",
        "    def forward(self, x: pt.Tensor) -> pt.Tensor:\n",
        "        x = x.view(x.size(0), -1)  # Flatten image [B, 1, 28, 28] -> [B, 784]\n",
        "        x = F.relu(self.input_layer(x))\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = F.relu(self.hidden_layer(x))\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        x = self.output_layer(x)\n",
        "        x = F.softmax(x, dim=1)  # Softmax for classification probabilities\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yN435-5R7vM"
      },
      "source": [
        "---\n",
        "\n",
        "*End of Task 3. Copy your final code to **Homework 2 - Code** on **NextIlearn***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-CyJ1C2k5Uh"
      },
      "source": [
        "**Alternative but more restrictive:** `torch.nn.Sequential`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgCnKX8uk5Ui"
      },
      "outputs": [],
      "source": [
        "from torch.nn import Sequential\n",
        "from collections import OrderedDict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74qg0-yyk5Ui"
      },
      "source": [
        "Unnamed layers:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMFyempxk5Ui"
      },
      "outputs": [],
      "source": [
        "model = Sequential(\n",
        "    nn.Linear(in_features=784, out_features=100, bias=True),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(in_features=100, out_features=len(class_names), bias=True),\n",
        "    nn.Softmax(dim=-1)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k17S9U77k5Ui"
      },
      "source": [
        "Named layers:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_wVfoB2k5Uj"
      },
      "outputs": [],
      "source": [
        "model = Sequential(OrderedDict([\n",
        "    ('layer1',      nn.Linear(in_features=784, out_features=100, bias=True)),\n",
        "    ('activation1', nn.ReLU()),\n",
        "    ('layer1',      nn.Linear(in_features=100, out_features=len(class_names), bias=True)),\n",
        "    ('activation2', nn.Softmax(dim=-1))\n",
        "]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWo7nYEYp-Wb"
      },
      "source": [
        "### Section 3: Training the network:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2Q14ZHssu1E"
      },
      "source": [
        "In PyTorch one needs to define which device to use for computation. All tensors involved in the computation need to be on that device. The most common devices are:\n",
        "- `cpu`: any of your computer's CPUs\n",
        "- `cpu:0`:the first of your computer's CPUs\n",
        "- `cuda`: any of your computer's GPUs\n",
        "- `cuda:2`: the third GPU of you computer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9HxsXGisi9T",
        "outputId": "e2fd74c1-c7fe-4c45-91ce-4525c3e476d6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ],
      "source": [
        "# get gpu if available else cpu:\n",
        "device = pt.device(\"cuda\" if pt.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qs-4FS3uKsMZ"
      },
      "outputs": [],
      "source": [
        "# move a model or tensor to the device:\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zuZAZKxtFBFR"
      },
      "source": [
        "Prediction on new instances:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SdDh74y0i7fX"
      },
      "outputs": [],
      "source": [
        "# X_new = pt.tensor(X_test[:3], dtype=pt.float32, device=device)\n",
        "# y_proba = model(X_new) # this returns a probability?\n",
        "# y_proba = y_proba.detach().cpu().numpy() # to numpy\n",
        "# y_proba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nU8cAN3fi99y"
      },
      "outputs": [],
      "source": [
        "# np.array(class_names)[np.argmax(y_proba, axis=1)] #if we want to know the class names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9wLOuG8vK_r"
      },
      "source": [
        "Instances of `torch.nn.Module` have a method `.train()` and a method `.eval()` that set the whole module (including submodules) in a training or prediction mode.\n",
        "\n",
        "This is necessary, as for example dropout layers are inactive during prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIRxMYLRqnoU"
      },
      "source": [
        "In order to train the network, we need to define a training procedure:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FqjxNg_mDP2z"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import f1_score\n",
        "from typing import Optional, Callable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aBxz4ZXkz4hT"
      },
      "outputs": [],
      "source": [
        "def epoch(model:CustomNetwork, loader_train:DataLoader, optimizer:pt.optim.Optimizer, loss_fn:Callable[[pt.Tensor, pt.Tensor], pt.Tensor]):\n",
        "  # 1. set model to train:\n",
        "  model.train()\n",
        "\n",
        "  losses = None if loss_fn is None else []\n",
        "  with pt.enable_grad():\n",
        "    for X_batch, y_batch in loader_train:\n",
        "      # move tensors to correct device:\n",
        "      X_batch = X_batch.to(device)\n",
        "      y_batch = y_batch.to(device)\n",
        "\n",
        "      # reset all gradients to zero:\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # create predictions:\n",
        "      y_pred = model(X_batch)\n",
        "\n",
        "      # calculate loss:\n",
        "      loss = loss_fn(y_pred, y_batch)\n",
        "      losses.append(loss_fn(y_pred, y_batch).detach().cpu().numpy())\n",
        "\n",
        "      # backpropagate loss:\n",
        "      loss.backward()\n",
        "\n",
        "      # update weights:\n",
        "      optimizer.step()\n",
        "\n",
        "  return np.mean(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "adSjw6i50L3b"
      },
      "outputs": [],
      "source": [
        "def evaluate(model:CustomNetwork, loader_valid:DataLoader, loss_fn:Optional[Callable[[pt.Tensor, pt.Tensor], pt.Tensor]]=None):\n",
        "  # 1. set model to eval:\n",
        "  model.eval()\n",
        "\n",
        "  labels = []\n",
        "  predictions = []\n",
        "  losses = None if loss_fn is None else []\n",
        "  for X_batch, y_batch in loader_valid:\n",
        "    # move tensors to correct device:\n",
        "    X_batch = X_batch.to(device)\n",
        "    y_batch = y_batch.to(device)\n",
        "    labels.extend(y_batch.cpu().detach().numpy())\n",
        "\n",
        "    # create predictions:\n",
        "    y_pred = model(X_batch)\n",
        "    predictions.extend(y_pred.cpu().detach().numpy())\n",
        "\n",
        "    # calculate loss:\n",
        "    if loss_fn is not None:\n",
        "      losses.append(loss_fn(y_pred, y_batch).detach().cpu().numpy())\n",
        "\n",
        "  # calculate f1 score:\n",
        "  f1 = f1_score(\n",
        "    y_batch.cpu().detach().numpy(),\n",
        "    y_pred.argmax(dim=1).cpu().detach().numpy(),\n",
        "    average='macro'\n",
        "  )\n",
        "\n",
        "  if loss_fn is None: return {'f1':f1}\n",
        "  else: return {'loss':np.mean(losses), 'f1':f1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SASZ5PCXq4tr"
      },
      "outputs": [],
      "source": [
        "def fit(model:CustomNetwork, loader_train:DataLoader, loader_valid:DataLoader, epochs:int, lr:float):\n",
        "  # instantiate optimizer:\n",
        "  optimizer = pt.optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "  # instantiate loss function:\n",
        "  loss_fn = pt.nn.CrossEntropyLoss()\n",
        "\n",
        "  history = []\n",
        "  for i in range(epochs):\n",
        "    # train for one epoch:\n",
        "    loss_train = epoch(model, loader_train, optimizer, loss_fn)\n",
        "\n",
        "    # evaluate on validation:\n",
        "    metrics = evaluate(model, loader_valid, loss_fn)\n",
        "\n",
        "    # save metrics:\n",
        "    history.append({\n",
        "      'loss_train':loss_train,\n",
        "      'loss_valid': metrics['loss'],\n",
        "      'f1_valid': metrics['f1']\n",
        "    })\n",
        "\n",
        "    # print message:\n",
        "    print(f'Epoch {i+1:d}/{epochs:d}:', *[f'{metric} = {history[-1][metric]:.2f};' for metric in history[-1]], sep='\\t')\n",
        "\n",
        "  # return history:\n",
        "  return pd.DataFrame(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q08uZrmWMCmq"
      },
      "source": [
        "Fit the model for 30 epochs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "U1VqXewrMCVQ",
        "outputId": "299ce7fa-36d5-46e0-c985-73f5e3a46d8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30:\tloss_train = 2.29;\tloss_valid = 2.27;\tf1_valid = 0.41;\n",
            "Epoch 2/30:\tloss_train = 2.15;\tloss_valid = 2.00;\tf1_valid = 0.36;\n",
            "Epoch 3/30:\tloss_train = 1.91;\tloss_valid = 1.84;\tf1_valid = 0.51;\n",
            "Epoch 4/30:\tloss_train = 1.83;\tloss_valid = 1.79;\tf1_valid = 0.59;\n",
            "Epoch 5/30:\tloss_train = 1.79;\tloss_valid = 1.77;\tf1_valid = 0.59;\n",
            "Epoch 6/30:\tloss_train = 1.77;\tloss_valid = 1.74;\tf1_valid = 0.62;\n",
            "Epoch 7/30:\tloss_train = 1.74;\tloss_valid = 1.72;\tf1_valid = 0.66;\n",
            "Epoch 8/30:\tloss_train = 1.72;\tloss_valid = 1.70;\tf1_valid = 0.68;\n",
            "Epoch 9/30:\tloss_train = 1.71;\tloss_valid = 1.69;\tf1_valid = 0.68;\n",
            "Epoch 10/30:\tloss_train = 1.70;\tloss_valid = 1.69;\tf1_valid = 0.69;\n",
            "Epoch 11/30:\tloss_train = 1.69;\tloss_valid = 1.68;\tf1_valid = 0.73;\n",
            "Epoch 12/30:\tloss_train = 1.69;\tloss_valid = 1.68;\tf1_valid = 0.73;\n",
            "Epoch 13/30:\tloss_train = 1.69;\tloss_valid = 1.68;\tf1_valid = 0.75;\n",
            "Epoch 14/30:\tloss_train = 1.68;\tloss_valid = 1.67;\tf1_valid = 0.73;\n",
            "Epoch 15/30:\tloss_train = 1.68;\tloss_valid = 1.67;\tf1_valid = 0.75;\n",
            "Epoch 16/30:\tloss_train = 1.68;\tloss_valid = 1.67;\tf1_valid = 0.75;\n",
            "Epoch 17/30:\tloss_train = 1.67;\tloss_valid = 1.67;\tf1_valid = 0.73;\n",
            "Epoch 18/30:\tloss_train = 1.67;\tloss_valid = 1.67;\tf1_valid = 0.75;\n",
            "Epoch 19/30:\tloss_train = 1.67;\tloss_valid = 1.66;\tf1_valid = 0.73;\n",
            "Epoch 20/30:\tloss_train = 1.67;\tloss_valid = 1.66;\tf1_valid = 0.73;\n",
            "Epoch 21/30:\tloss_train = 1.67;\tloss_valid = 1.66;\tf1_valid = 0.75;\n",
            "Epoch 22/30:\tloss_train = 1.66;\tloss_valid = 1.66;\tf1_valid = 0.75;\n",
            "Epoch 23/30:\tloss_train = 1.66;\tloss_valid = 1.66;\tf1_valid = 0.73;\n",
            "Epoch 24/30:\tloss_train = 1.66;\tloss_valid = 1.66;\tf1_valid = 0.73;\n",
            "Epoch 25/30:\tloss_train = 1.66;\tloss_valid = 1.66;\tf1_valid = 0.75;\n",
            "Epoch 26/30:\tloss_train = 1.66;\tloss_valid = 1.66;\tf1_valid = 0.75;\n",
            "Epoch 27/30:\tloss_train = 1.66;\tloss_valid = 1.66;\tf1_valid = 0.75;\n",
            "Epoch 28/30:\tloss_train = 1.66;\tloss_valid = 1.66;\tf1_valid = 0.75;\n",
            "Epoch 29/30:\tloss_train = 1.66;\tloss_valid = 1.65;\tf1_valid = 0.75;\n",
            "Epoch 30/30:\tloss_train = 1.65;\tloss_valid = 1.65;\tf1_valid = 0.75;\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='epoch', ylabel='loss'>"
            ]
          },
          "metadata": {},
          "execution_count": 131
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# instantiate model and move to device:\n",
        "model = CustomNetwork().to(device)\n",
        "\n",
        "# train model:\n",
        "history = fit(model, loader_train, loader_valid, epochs=30, lr=.01)\n",
        "\n",
        "# plot history:\n",
        "history[['loss_train', 'loss_valid']].plot(xlabel='epoch', ylabel='loss')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qmHUt5M_nQd"
      },
      "source": [
        "**Evaluation**: `evaluate` will return the metric scores!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMdArSMDi8BI",
        "outputId": "81f5ee01-f183-4610-8daf-8fc960a652fd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'f1': 0.7659090909090909}"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ],
      "source": [
        "evaluate(model, loader_test) #evaluate on the test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kw1ZVmrTk5Un"
      },
      "source": [
        "How does SGD work?\n",
        "\n",
        "<img src=\"https://pantelis.github.io/cs677/docs/common/lectures/optimization/sgd/images/gradient-descent.png\" alt=\"gradient-descent.png\" style=\"width:500px;\"/>\n",
        "\n",
        "Can be improved by:\n",
        " - ... reducing the stepsize (i.e. `lr`) towards the end\n",
        " - ... using momentum to keep a clear trajectory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcSUB0uJTPBg"
      },
      "source": [
        "---\n",
        "\n",
        "<span style=\"color:red\"><b>TASK 4</b> - Improved Training:</span>\n",
        "\n",
        "---\n",
        "\n",
        "Improve the above training loop with the following steps:\n",
        "1. replace the very basic SGD optimizer with the momentum-based [`torch.optim.Adam`](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html) optimizer. Compare how the learning curves change after this step. **As ADAM is more sensitive to the learning rate, set it to `0.001` after changing the optimizer!**\n",
        "2. add a [`torch.optim.lr_scheduler.LinearLR`](https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.LinearLR.html) scheduler (_start: `1.0*lr`, end:`0.33*lr`, over 10 epochs_).  Compare how the learning curves change after this step.\n",
        "3. add an **early stopping** functionality, that stops training when the validation loss has not improved for `patience` epochs and restores the model parameters to the ones achieving the best loss. **Use a patience of `5` to retrain the network.**\n",
        "\n",
        "**Disclaimer:** *We will not check whether you actually compare the loss curves before and after adding a specific step. But we may ask about their impact in the final exam.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pwOaMCDSTOpS"
      },
      "outputs": [],
      "source": [
        "def epoch(model:CustomNetwork, loader_train:DataLoader, optimizer:pt.optim.Optimizer, loss_fn:Callable[[pt.Tensor, pt.Tensor], pt.Tensor]):\n",
        "  model.train()\n",
        "  device = next(model.parameters()).device  # Get device from model parameters\n",
        "  total_loss = 0.0\n",
        "  for inputs, targets in loader_train:\n",
        "    inputs, targets = inputs.to(device), targets.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(inputs)\n",
        "    loss = loss_fn(outputs, targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    total_loss += loss.item() * inputs.size(0)\n",
        "  return total_loss / len(loader_train.dataset)\n",
        "\n",
        "def evaluate(model:CustomNetwork, loader_valid:DataLoader, loss_fn:Optional[Callable[[pt.Tensor, pt.Tensor], pt.Tensor]]=None):\n",
        "\n",
        "  model.eval()\n",
        "  device = next(model.parameters()).device  # Get device from model parameters\n",
        "  total_loss = 0.0\n",
        "  all_targets = []\n",
        "  all_outputs = []\n",
        "  with pt.no_grad():\n",
        "    for inputs, targets in loader_valid:\n",
        "      inputs, targets = inputs.to(device), targets.to(device)\n",
        "      outputs = model(inputs)\n",
        "      if loss_fn is not None:\n",
        "        total_loss += loss_fn(outputs, targets).item() * inputs.size(0)\n",
        "        all_targets.append(targets.cpu().numpy())\n",
        "        all_outputs.append(outputs.argmax(dim=1).cpu().numpy())\n",
        "  avg_loss = total_loss / len(loader_valid.dataset) if loss_fn is not None else None\n",
        "  all_targets = np.concatenate(all_targets)\n",
        "  all_outputs = np.concatenate(all_outputs)\n",
        "  f1 = f1_score(all_targets, all_outputs, average='macro')\n",
        "  return avg_loss, f1\n",
        "\n",
        "def fit(model:CustomNetwork, loader_train:DataLoader, loader_valid:DataLoader, epochs:int, lr:float, patience:int):\n",
        "  optimizer = pt.optim.Adam(model.parameters(), lr=lr)\n",
        "  scheduler = pt.optim.lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=0.33, total_iters=10)\n",
        "  loss_fn = pt.nn.CrossEntropyLoss()\n",
        "\n",
        "  best_loss = float('inf')\n",
        "  best_epoch = 0\n",
        "  best_state = model.state_dict()\n",
        "  no_improvement = 0\n",
        "\n",
        "  train_losses, valid_losses, valid_f1s = [], [], []\n",
        "\n",
        "  for epoch_idx in range(epochs):\n",
        "    train_loss = epoch(model, loader_train, optimizer, loss_fn)\n",
        "    valid_loss, valid_f1 = evaluate(model, loader_valid, loss_fn)\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "    valid_f1s.append(valid_f1)\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    if valid_loss < best_loss:\n",
        "      best_loss = valid_loss\n",
        "      best_epoch = epoch_idx\n",
        "      best_state = model.state_dict()\n",
        "      no_improvement = 0\n",
        "    else:\n",
        "      no_improvement += 1\n",
        "      if no_improvement >= patience:\n",
        "        model.load_state_dict(best_state)\n",
        "        break\n",
        "\n",
        "  return {\n",
        "      'train_losses': train_losses,\n",
        "      'valid_losses': valid_losses,\n",
        "      'valid_f1s': valid_f1s,\n",
        "      'best_epoch': best_epoch\n",
        "  }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9r-hDPkRUY0R"
      },
      "source": [
        "---\n",
        "\n",
        "*End of Task 4. Copy your final code to **Homework 2 - Code** on **NextIlearn***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKm2rIvKUP2C"
      },
      "source": [
        "### Section 4: Other useful and frequently used functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fp4BHXYqUWBH"
      },
      "source": [
        "Save and load the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBmnCPTdaAlV"
      },
      "source": [
        "**Option 1:** `torch.save(...)` / `torch.load(...)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQIhSX16UXpR"
      },
      "outputs": [],
      "source": [
        "pt.save(model, 'model.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrmRkkvbVYqj",
        "outputId": "a5de8aa6-89e8-4702-add8-1abd58efeda3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  model.pt\n",
            "replace model/data.pkl? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            " extracting: model/data.pkl          \n",
            "replace model/byteorder? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            " extracting: model/byteorder         \n",
            "replace model/data/0? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            " extracting: model/data/0            \n",
            "replace model/data/1? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            " extracting: model/data/1            \n",
            "replace model/data/2? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            " extracting: model/data/2            \n",
            "replace model/data/3? [y]es, [n]o, [A]ll, [N]one, [r]ename: a\n",
            "error:  invalid response [a]\n",
            "replace model/data/3? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            " extracting: model/data/3            \n",
            "replace model/data/4? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            " extracting: model/data/4            \n",
            "replace model/data/5? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "# this saves a zipfile!\n",
        "!unzip model.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sexXOBTKUZH_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb7f0e3a-8e89-4793-d402-d0bf25684bd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                  [-1, 300]         235,500\n",
            "           Dropout-2                  [-1, 300]               0\n",
            "            Linear-3                  [-1, 200]          60,200\n",
            "           Dropout-4                  [-1, 200]               0\n",
            "            Linear-5                   [-1, 10]           2,010\n",
            "================================================================\n",
            "Total params: 297,710\n",
            "Trainable params: 297,710\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.01\n",
            "Params size (MB): 1.14\n",
            "Estimated Total Size (MB): 1.15\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "model = pt.load('model.pt', weights_only=False) # \"weights_only = True\" only loads PyTorch Tensors in the model file!\n",
        "summary(model, input_size=(784,))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cr88yK-8Z5GY"
      },
      "source": [
        "**Option 2:** save/load state_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FsXhrkFhZ9NY"
      },
      "outputs": [],
      "source": [
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44MB9qujUPys"
      },
      "outputs": [],
      "source": [
        "with open('model_state_dict.pkl', 'wb') as f:\n",
        "  pickle.dump(model.state_dict(), f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_CuVaeSJZgW0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5e9b2a7-d3bd-47ee-dc53-e0f670999bd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                  [-1, 300]         235,500\n",
            "           Dropout-2                  [-1, 300]               0\n",
            "            Linear-3                  [-1, 200]          60,200\n",
            "           Dropout-4                  [-1, 200]               0\n",
            "            Linear-5                   [-1, 10]           2,010\n",
            "================================================================\n",
            "Total params: 297,710\n",
            "Trainable params: 297,710\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.01\n",
            "Params size (MB): 1.14\n",
            "Estimated Total Size (MB): 1.15\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "with open('model_state_dict.pkl', 'rb') as f:\n",
        "  state_dict = pickle.load(f)\n",
        "model.load_state_dict(state_dict)\n",
        "summary(model, input_size=(784,))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w003CKN5R7vY"
      },
      "source": [
        "---\n",
        "\n",
        "<span style=\"color:red\"><b>TASK 5</b> - Regression MLP</span>\n",
        "\n",
        "---\n",
        "\n",
        "We have created a classification model on Fashion MNIST with PyTorch. In addition, we can of course use similar PyTorch models to solve regression tasks. **How can we do that?** Which part should we change to make it work on regression tasks? That would be our last task in this lab. Based on your knowledge from the second lecture, you may be able to figure out which part you need to change.\n",
        "\n",
        "Create a regression model by adapting the PyTorch model we used above and train it on the [california housing dataset](https://nextilearn.dsv.su.se/mod/resource/view.php?id=25386 ).\n",
        "You may need to change **a loss function** and input / output layers as we no longer deal with images and classification. Feel free to use scikit-learn but we still recommend you to practice preprocessing with NumPy for your skills.\n",
        "\n",
        "**Upload the resulting predictions to NextIlearn. Your model should achieve an MSE < XXX to pass.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qforG1NGbEuq"
      },
      "source": [
        "1. Get training and test data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YpmUlavla3Py",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db492154-325a-48b9-cca2-624c54b4888b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  data.zip\n",
            "replace data/task5/data_train.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['data_train.csv', 'data_test.csv', 'description.md', 'labels_train.csv']"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ],
      "source": [
        "# 1.1 you should have received a zip folder \"data.zip\" along with this notebook\n",
        "\n",
        "# 1.2 unzip data.zip\n",
        "!unzip data.zip\n",
        "\n",
        "# 1.3 check files:\n",
        "os.listdir('data/task5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYYglS3ybCM8"
      },
      "source": [
        "2. Create Data Pipeline:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQ_Rj925R7vY"
      },
      "outputs": [],
      "source": [
        "# 2.1 load training data:\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "data_train = pd.read_csv('data/task5/data_train.csv', index_col=0)\n",
        "labels_train = pd.read_csv('data/task5/labels_train.csv', index_col=0)\n",
        "\n",
        "# 2.2 load test data (no labels):\n",
        "data_test = pd.read_csv('data/task5/data_test.csv', index_col=0)\n",
        "\n",
        "#...\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(data_train.values)\n",
        "y_train = labels_train.values.reshape(-1, 1)\n",
        "X_test = scaler.transform(data_test.values)\n",
        "\n",
        "X_train_tensor = torch.FloatTensor(X_train)\n",
        "y_train_tensor = torch.FloatTensor(y_train)\n",
        "X_test_tensor = torch.FloatTensor(X_test)\n",
        "\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaRz2hDYbYJ6"
      },
      "source": [
        "3. Create Model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nl0-sMfCR7vZ"
      },
      "outputs": [],
      "source": [
        "#...\n",
        "class HousingModel(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(HousingModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 32)\n",
        "        self.fc4 = nn.Linear(32, 1)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "\n",
        "model = HousingModel(input_size=X_train.shape[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzSyLqesbkYc"
      },
      "source": [
        "4. Train model on `data_train` and `labels_train`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_dqM_Yzyb1ho",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "952e249e-fc18-455a-aeaa-69e316b1037b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping at epoch 95\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "#...\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 100\n",
        "best_loss = float('inf')\n",
        "patience = 10\n",
        "no_improvement = 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, targets in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    scheduler.step(epoch_loss)\n",
        "\n",
        "    if epoch_loss < best_loss:\n",
        "        best_loss = epoch_loss\n",
        "        no_improvement = 0\n",
        "        torch.save(model.state_dict(), 'best_model.pth')\n",
        "    else:\n",
        "        no_improvement += 1\n",
        "        if no_improvement >= patience:\n",
        "            print(f'Early stopping at epoch {epoch}')\n",
        "            break\n",
        "\n",
        "model.load_state_dict(torch.load('best_model.pth'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ipIi84zb5ZR"
      },
      "source": [
        "5. Predict `data_test` and save predictions to `submission.csv`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_gqdJvucm2l"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    predictions = model(X_test_tensor) #...\n",
        "\n",
        "pd.DataFrame(predictions.detach().cpu().numpy(), columns=['predictions']).to_csv('submission.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aB-ezFJER7vZ"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}